{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hERG - QSAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 : Import the libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # 'panel data' makes easy to manipulate data\n",
    "import numpy as np                      # to allow to generate random  numbers \n",
    "\n",
    "import matplotlib.pyplot as plt                # to draw graphs\n",
    "import seaborn as sns                          # ...\n",
    "import plotly.express as px                    # ...\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier                   # to build a random forest classifier \n",
    "from sklearn.tree import DecisionTreeClassifier                       # to build a classification tree\n",
    "\n",
    "import statistics                                                     # to realise statistic calculations\n",
    "import itertools                                                      # to flatten lists \n",
    "from operator import index                                            # to find the index of items in a list\n",
    "\n",
    "from sklearn.metrics import confusion_matrix                          # to create a confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix                     # to plot confusion matrix\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score                   # to load metrics\n",
    "from sklearn.metrics import matthews_corrcoef                         # ... \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV                # to perform Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV                      # ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 : Import data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SMILES_new</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>qed</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>NumHAcceptors</th>\n",
       "      <th>NumHDonors</th>\n",
       "      <th>MolLogP</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>...</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>desalted\\demetalled</th>\n",
       "      <th>mixture</th>\n",
       "      <th>complex</th>\n",
       "      <th>changes</th>\n",
       "      <th>Clusters</th>\n",
       "      <th>fingerprint</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Cc1cc(C)n(-c2cc(NC(=O)CCN(C)C)nc(-c3ccc(C)o3)n...</td>\n",
       "      <td>368.196074</td>\n",
       "      <td>0.719563</td>\n",
       "      <td>1.962963</td>\n",
       "      <td>89.08</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.73776</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.187087</td>\n",
       "      <td>AACWUFIIMOHGSO-UHFFFAOYSA-N</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>PICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Cc1ccc(NC(=O)C(COC(C)C)Oc2ncnc3c2cnn3-c2ncccc2...</td>\n",
       "      <td>467.147265</td>\n",
       "      <td>0.418807</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>116.94</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.37842</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAGISEXHOPCAHZ-UHFFFAOYSA-N</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>PICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Cc1ncoc1-c1nnc(SCCCN2CCC3(CC3c3ccccc3)C2)n1C</td>\n",
       "      <td>409.193631</td>\n",
       "      <td>0.431725</td>\n",
       "      <td>2.103448</td>\n",
       "      <td>59.98</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.14032</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>AAPXNHMQKBDDJN-UHFFFAOYNA-N</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>PICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>CN(C)Cc1ccc(C(F)(F)F)cc1Oc1ccc(Cl)c(Cl)c1</td>\n",
       "      <td>363.040454</td>\n",
       "      <td>0.673225</td>\n",
       "      <td>1.695652</td>\n",
       "      <td>12.47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.86610</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.950782</td>\n",
       "      <td>AAQZZAVVFRIEOD-UHFFFAOYSA-N</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>PICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>O=C(Cc1ccc(-n2cnnn2)cc1)N1CCN(CCc2ccc3c(c2)COC...</td>\n",
       "      <td>418.211724</td>\n",
       "      <td>0.605615</td>\n",
       "      <td>1.709677</td>\n",
       "      <td>76.38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.62190</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.602060</td>\n",
       "      <td>AAYRYIFNKRSGOF-UHFFFAOYSA-N</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVec...</td>\n",
       "      <td>PICKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         SMILES_new  ExactMolWt  \\\n",
       "0           2  Cc1cc(C)n(-c2cc(NC(=O)CCN(C)C)nc(-c3ccc(C)o3)n...  368.196074   \n",
       "1           4  Cc1ccc(NC(=O)C(COC(C)C)Oc2ncnc3c2cnn3-c2ncccc2...  467.147265   \n",
       "2           5       Cc1ncoc1-c1nnc(SCCCN2CCC3(CC3c3ccccc3)C2)n1C  409.193631   \n",
       "3           6          CN(C)Cc1ccc(C(F)(F)F)cc1Oc1ccc(Cl)c(Cl)c1  363.040454   \n",
       "4          10  O=C(Cc1ccc(-n2cnnn2)cc1)N1CCN(CCc2ccc3c(c2)COC...  418.211724   \n",
       "\n",
       "        qed  FpDensityMorgan2    TPSA  NumHAcceptors  NumHDonors  MolLogP  \\\n",
       "0  0.719563          1.962963   89.08            7.0         1.0  2.73776   \n",
       "1  0.418807          2.000000  116.94            9.0         1.0  3.37842   \n",
       "2  0.431725          2.103448   59.98            7.0         0.0  4.14032   \n",
       "3  0.673225          1.695652   12.47            2.0         0.0  5.86610   \n",
       "4  0.605615          1.709677   76.38            7.0         0.0  1.62190   \n",
       "\n",
       "   FractionCSP3  ...  Outcome     pIC50                     InChIKey  \\\n",
       "0      0.368421  ...        1  6.187087  AACWUFIIMOHGSO-UHFFFAOYSA-N   \n",
       "1      0.272727  ...        0       NaN  AAGISEXHOPCAHZ-UHFFFAOYSA-N   \n",
       "2      0.500000  ...        1  5.420000  AAPXNHMQKBDDJN-UHFFFAOYNA-N   \n",
       "3      0.250000  ...        1  5.950782  AAQZZAVVFRIEOD-UHFFFAOYSA-N   \n",
       "4      0.391304  ...        1  5.602060  AAYRYIFNKRSGOF-UHFFFAOYSA-N   \n",
       "\n",
       "   desalted\\demetalled  mixture  complex  changes Clusters  \\\n",
       "0                False    False    False      NaN        2   \n",
       "1                False    False    False      NaN        4   \n",
       "2                False    False    False      NaN        5   \n",
       "3                False    False    False      NaN        6   \n",
       "4                False    False    False      NaN        7   \n",
       "\n",
       "                                         fingerprint     ID  \n",
       "0  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...  PICKS  \n",
       "1  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...  PICKS  \n",
       "2  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...  PICKS  \n",
       "3  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...  PICKS  \n",
       "4  <rdkit.DataStructs.cDataStructs.ExplicitBitVec...  PICKS  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataframe with picks.csv')                          # to download the data from the file into a dataframe called df\n",
    "df.head()                                                             # to view the top 5 rows \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 : Identify anomalies or missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    int64\n",
       "SMILES_new                   object\n",
       "ExactMolWt                  float64\n",
       "qed                         float64\n",
       "FpDensityMorgan2            float64\n",
       "TPSA                        float64\n",
       "NumHAcceptors               float64\n",
       "NumHDonors                  float64\n",
       "MolLogP                     float64\n",
       "FractionCSP3                float64\n",
       "NumRotatableBonds           float64\n",
       "HeavyAtomCount              float64\n",
       "NumAliphaticCarbocycles     float64\n",
       "NumAromaticCarbocycles      float64\n",
       "NumAliphaticHeterocycles    float64\n",
       "NumAromaticHeterocycles     float64\n",
       "NumAromaticRings            float64\n",
       "Compound_name                object\n",
       "Standard Relation            object\n",
       "IC50_nM                     float64\n",
       "Outcome                       int64\n",
       "pIC50                       float64\n",
       "InChIKey                     object\n",
       "desalted\\demetalled            bool\n",
       "mixture                        bool\n",
       "complex                        bool\n",
       "changes                      object\n",
       "Clusters                      int64\n",
       "fingerprint                  object\n",
       "ID                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # to tell the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71956264, 0.41880677, 0.43172538, ..., 0.29413806, 0.56564395,\n",
       "       0.48294608])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qed'].unique() # to test printing a unique value in the column 2 for qed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 (1800, 30)\n",
      "SMILES_new (1800, 30)\n",
      "ExactMolWt (1800, 30)\n",
      "qed (1800, 30)\n",
      "FpDensityMorgan2 (1800, 30)\n",
      "TPSA (1800, 30)\n",
      "NumHAcceptors (1800, 30)\n",
      "NumHDonors (1800, 30)\n",
      "MolLogP (1800, 30)\n",
      "FractionCSP3 (1800, 30)\n",
      "NumRotatableBonds (1800, 30)\n",
      "HeavyAtomCount (1800, 30)\n",
      "NumAliphaticCarbocycles (1800, 30)\n",
      "NumAromaticCarbocycles (1800, 30)\n",
      "NumAliphaticHeterocycles (1800, 30)\n",
      "NumAromaticHeterocycles (1800, 30)\n",
      "NumAromaticRings (1800, 30)\n",
      "Compound_name (1800, 30)\n",
      "Standard Relation (1800, 30)\n",
      "IC50_nM (1800, 30)\n",
      "Outcome (1800, 30)\n",
      "pIC50 (1341, 30)\n",
      "InChIKey (1800, 30)\n",
      "desalted\\demetalled (1800, 30)\n",
      "mixture (1800, 30)\n",
      "complex (1800, 30)\n",
      "changes (5, 30)\n",
      "Clusters (1800, 30)\n",
      "fingerprint (1800, 30)\n",
      "ID (1800, 30)\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, df[-df[col].isna()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 3 : Decison Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the Decision Tree :\n",
      "fold1 - MCC: 0.26839804517998356, ACC: 0.632992327365729\n",
      "fold1 - Optimal Alpha : 0.0029045948283003553\n",
      "fold2 - MCC: 0.20394534103468318, ACC: 0.6043810155990708\n",
      "fold2 - Optimal Alpha : 0.004414720430076305\n",
      "fold3 - MCC: 0.26439680538041194, ACC: 0.632198402690206\n",
      "fold3 - Optimal Alpha : 0.010889015898933208\n",
      "fold4 - MCC: 0.2807524417899684, ACC: 0.640153452685422\n",
      "fold4 - Optimal Alpha : 0.003028216376104856\n",
      "fold5 - MCC: 0.29641075567784275, ACC: 0.6466747646522928\n",
      "fold5 - Optimal Alpha : 0.004237183638218164\n",
      "fold6 - MCC: 0.2847207731332163, ACC: 0.636\n",
      "fold6 - Optimal Alpha : 0.003520556546807517\n",
      "fold7 - MCC: 0.22663591891647744, ACC: 0.6118931048551611\n",
      "fold7 - Optimal Alpha : 0.0027236001868144316\n",
      "fold8 - MCC: 0.07044373768981514, ACC: 0.5309983896940419\n",
      "fold8 - Optimal Alpha : 0.005023855569293759\n",
      "fold-1 - MCC: 0.11582175587333282, ACC: 0.558786078098472\n",
      "fold-1 - Optimal Alpha : 0.015799666854435235\n",
      " Aggregate MCC: 0.23113930967761867 - Aggregate ACC 0.6155439698073701\n",
      "MCC mean: 0.22350284163063683 ; ACC mean : 0.6104530595155995\n"
     ]
    }
   ],
   "source": [
    "# 1. dictionaries containing the results of the model, parameters and metrics per cluster\n",
    "\n",
    "dict_metrics_dt = {'mcc' : [], 'acc' : []}\n",
    "\n",
    "dict_y_pred_dt = {}\n",
    "\n",
    "dict_y_eval_dt = {}\n",
    "\n",
    "dict_alpha = {1: 0.0029045948283003553,\n",
    " 2: 0.004414720430076305,\n",
    " 3: 0.010889015898933208,\n",
    " 4: 0.003028216376104856,\n",
    " 5: 0.004237183638218164,\n",
    " 6: 0.003520556546807517,\n",
    " 7: 0.0027236001868144316,\n",
    " 8: 0.005023855569293759,\n",
    " -1: 0.015799666854435235}\n",
    "\n",
    "\n",
    "\n",
    "print('Results of the Decision Tree :')\n",
    "\n",
    "# 2. to set the for loop of the one-cluster-out cross-validation\n",
    "\n",
    "for i in set(df.Clusters):\n",
    "\n",
    "    clf_dts = []           # an array to contain all the decision trees\n",
    "\n",
    "\n",
    "    # 3. to split the dataset into evaluation and training\n",
    "    \n",
    "    evaluation = df[df.Clusters == i]         \n",
    "    training = df[-(df.Clusters == i)]\n",
    "    \n",
    "    X_train = training[['ExactMolWt','qed','FpDensityMorgan2','TPSA','NumHAcceptors','NumHDonors','MolLogP','FractionCSP3','NumRotatableBonds','HeavyAtomCount', 'NumAliphaticCarbocycles', 'NumAromaticCarbocycles', 'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumAromaticRings']]\n",
    "    Y_train = training['Outcome']\n",
    "\n",
    "    X_eval = evaluation[['ExactMolWt','qed','FpDensityMorgan2','TPSA','NumHAcceptors','NumHDonors','MolLogP','FractionCSP3','NumRotatableBonds','HeavyAtomCount', 'NumAliphaticCarbocycles', 'NumAromaticCarbocycles', 'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumAromaticRings']]\n",
    "    Y_eval = evaluation['Outcome']\n",
    "\n",
    "\n",
    "\n",
    "    # 4. to build Decision Tree Classifier model\n",
    "\n",
    "    clf_dt = DecisionTreeClassifier(random_state = 50)\n",
    "    clf_dt = clf_dt.fit(X_train, Y_train)\n",
    "\n",
    "    # 5. to perform a Cost Complexity Pruning\n",
    "\n",
    "    path = clf_dt.cost_complexity_pruning_path(X_train, Y_train)               # to determine values for alpha \n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities                  # to extract different values for alpha\n",
    "    ccp_alphas = ccp_alphas[:-1]                                               # to exclude the maximum value of alpha because it would prune all the tree leaving only the root\n",
    "\n",
    "    # For each alpha we will append our model to a list : \n",
    "    \n",
    "    \n",
    "    #for ccp_alpha in ccp_alphas:                                                  \n",
    "        #clf_dt = DecisionTreeClassifier(random_state=50, ccp_alpha=ccp_alpha)  # to assign every alpha to a specific decision tree \n",
    "        #clf_dt.fit(X_train, Y_train)                                           # to fit the decision trees to the training dataset \n",
    "        #clf_dts.append(clf_dt)                                                 # to add all the decision trees into the array\n",
    "    \n",
    "\n",
    "\n",
    "    # 6. accuracy vs alpha for training and testing sets\n",
    "\n",
    "    train_acc = []         # an array containing the training balanced_accuracy_score of all the decision trees\n",
    "    test_acc = []          # an array containing the testing balanced_accuracy_score of all the decision trees\n",
    " \n",
    "    for c in clf_dts: \n",
    "        y_train_pred = c.predict(X_train)                                   # to predict the score of the training dataset \n",
    "        y_test_pred = c.predict(X_eval)                                     # to predict the score of the testing dataset\n",
    "        train_acc.append(balanced_accuracy_score(y_train_pred, Y_train))    # to add training accuracy of all the decision trees into an array \n",
    "        test_acc.append(balanced_accuracy_score(y_test_pred, Y_eval))       # to add testing accuracy of all the decision trees into an array \n",
    "\n",
    "    #diff_acc = [abs(i-j) for i, j in zip(test_acc,train_acc)]\n",
    "    #index_test_acc = diff_acc.index(min(diff_acc))\n",
    "    \n",
    "    #for alpha in ccp_alphas :                                               # to determine the alpha value corresponding to the maximum value of the testing dataset\n",
    "        #if list(ccp_alphas).index(alpha) == index_test_acc :\n",
    "            #dict_alpha[i] = alpha\n",
    "\n",
    "\n",
    "    clf_dt_final = DecisionTreeClassifier(random_state=50, ccp_alpha=dict_alpha[i])\n",
    "    clf_dt_final.fit(X_train, Y_train) \n",
    "    y_pred = clf_dt_final.predict(X_eval)                                            # to predict the response for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "    # 7. to add the results into the dictionaries \n",
    "    \n",
    "    dict_y_pred_dt[i] = y_pred\n",
    "    dict_y_eval_dt[i] = Y_eval\n",
    "\n",
    "    mcc_dt= matthews_corrcoef(Y_eval, y_pred) \n",
    "    acc_dt= balanced_accuracy_score(Y_eval, y_pred, adjusted = False) \n",
    "\n",
    "    dict_metrics_dt['mcc'].append(mcc_dt)\n",
    "    dict_metrics_dt['acc'].append(acc_dt)\n",
    "\n",
    "    #plot_confusion_matrix(clf_dt, X_eval, Y_eval, display_labels=[\"Is a Blocker\", \"Is not a Blocker\"]) \n",
    "\n",
    "    print(f'fold{i} - MCC: {mcc_dt}, ACC: {acc_dt}')\n",
    "    print(f'fold{i} - Optimal Alpha : {dict_alpha[i]}')\n",
    "\n",
    "\n",
    "\n",
    "# 8. Aggregate and Mean of the metrics \n",
    "\n",
    "agg_y_pred_dt = list(itertools.chain.from_iterable(dict_y_pred_dt.values()))\n",
    "agg_y_eval_dt = list(itertools.chain.from_iterable(dict_y_eval_dt.values()))\n",
    "    \n",
    "agg_mcc_dt = matthews_corrcoef(agg_y_eval_dt, agg_y_pred_dt)\n",
    "agg_acc_dt = balanced_accuracy_score(agg_y_eval_dt, agg_y_pred_dt, adjusted = False)\n",
    "\n",
    "print(f' Aggregate MCC: {agg_mcc_dt} - Aggregate ACC {agg_acc_dt}')\n",
    "\n",
    "mean_mcc_dt = statistics.mean(list(dict_metrics_dt['mcc']))\n",
    "mean_acc_dt = statistics.mean(list(dict_metrics_dt['acc']))\n",
    "\n",
    "print(f'MCC mean: {mean_mcc_dt} ; ACC mean : {mean_acc_dt}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 4 : Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1 - MCC: 0.30105739770096623, ACC: 0.6442455242966751\n",
      "fold2 - MCC: 0.35500732783714833, ACC: 0.6726960947007412\n",
      "fold3 - MCC: 0.35296972131460014, ACC: 0.6793820933165196\n",
      "fold4 - MCC: 0.39492599031416875, ACC: 0.6992327365728901\n",
      "fold5 - MCC: 0.3040133698755911, ACC: 0.6524445794108715\n",
      "fold6 - MCC: 0.30983866769659335, ACC: 0.628\n",
      "fold7 - MCC: 0.2696762959982108, ACC: 0.6353529171766625\n",
      "fold8 - MCC: 0.19581549326569875, ACC: 0.5940016103059581\n",
      "fold-1 - MCC: 0.17885327041772822, ACC: 0.5918930390492361\n",
      " Aggregate MCC: 0.32000567905130345 - Aggregate ACC 0.6600020493852462\n",
      "MCC mean: 0.2957952816023006 ; ACC mean : 0.6441387327588394\n"
     ]
    }
   ],
   "source": [
    "# 1. dictionaries containing the results of the model, parameters and metrics per cluster\n",
    "\n",
    "dict_metrics_rf = {'mcc' : [], 'acc' : []}\n",
    "\n",
    "dict_max_depth = {1:25, 2: 25, 3: 25, 4: 25, 5: 25, 6: 25, 7: 50, 8: 50, -1: 25}\n",
    "dict_max_features = {1: 4, 2: 4, 3: 4, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, -1: 4}\n",
    "dict_min_samples_leaf = {1: 5, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 2, -1: 2}\n",
    "dict_min_samples_split = {1: 12, 2: 8, 3: 10, 4: 8, 5: 8, 6: 10, 7: 10, 8: 8, -1: 8}\n",
    "dict_n_estimators = {1: 500, 2: 800, 3: 1000, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, -1: 500}\n",
    "\n",
    "dict_rf_cluster = {}\n",
    "\n",
    "dict_y_pred_rf = {}\n",
    "\n",
    "dict_y_eval_rf = {}\n",
    "\n",
    "# 2. to set the for loop of the one-cluster-out cross-validation\n",
    "\n",
    "for i in set(df.Clusters):\n",
    "\n",
    "    # 3. to split the dataset into evaluation and training\n",
    "\n",
    "    evaluation = df[df.Clusters == i]          \n",
    "    training = df[-(df.Clusters == i)]\n",
    "\n",
    "    X_train = training[['ExactMolWt','qed','FpDensityMorgan2','TPSA','NumHAcceptors','NumHDonors','MolLogP','FractionCSP3','NumRotatableBonds','HeavyAtomCount', 'NumAliphaticCarbocycles', 'NumAromaticCarbocycles', 'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumAromaticRings']]\n",
    "    Y_train = training['Outcome']\n",
    "\n",
    "    X_eval = evaluation[['ExactMolWt','qed','FpDensityMorgan2','TPSA','NumHAcceptors','NumHDonors','MolLogP','FractionCSP3','NumRotatableBonds','HeavyAtomCount', 'NumAliphaticCarbocycles', 'NumAromaticCarbocycles', 'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumAromaticRings']]\n",
    "    Y_eval = evaluation['Outcome']\n",
    "\n",
    "\n",
    "\n",
    "    # 4. to create the parameter grid to realize GridSearchCV\n",
    "    \n",
    "   # param_grid = {                                                                                                  \n",
    "   # 'max_depth': [5, 25, 50, 75, 100],\n",
    "   # 'max_features': [4],\n",
    "   # 'min_samples_leaf': [2, 2, 5],\n",
    "   # 'min_samples_split': [8, 10, 12],\n",
    "   # 'n_estimators': [1, 500, 800, 1000]\n",
    "   # }\n",
    "\n",
    "\n",
    "\n",
    "    # 5. to build Random Forest Classifier models \n",
    "\n",
    "    rf = RandomForestClassifier(ccp_alpha=0.001419, random_state=50, max_depth=dict_max_depth[i], max_features=dict_max_features[i], min_samples_split=dict_min_samples_split[i], min_samples_leaf= dict_min_samples_leaf[i], n_estimators=dict_n_estimators[i])                                                 \n",
    "    #grid_search = GridSearchCV(estimator = rf, param_grid = dict_best_param_cluster[i], cv = 3, n_jobs = -1, verbose = 2)            # to initiate the grid search model with 5-fold cross validation \n",
    "    #grid_search.fit(X_train, Y_train)                                                                                # to fit the grid search to the data\n",
    "    \n",
    "    rf.fit(X_train, Y_train)                                                                                         # to build a forest of trees from the training set(X,Y)\n",
    "    y_pred = rf.predict(X_eval)                                                                                      # to predict the response for the test dataset                \n",
    "    \n",
    "\n",
    "\n",
    "    # 6. to add the results into the dictionaries\n",
    "\n",
    "    dict_rf_cluster[i] = y_pred\n",
    "\n",
    "    #dict_best_param_cluster[i] = grid_search.best_params_                                                                         \n",
    "\n",
    "    mcc_rf= matthews_corrcoef(Y_eval, y_pred) \n",
    "    acc_rf= balanced_accuracy_score(Y_eval, y_pred, adjusted = False) \n",
    "\n",
    "    dict_y_pred_rf[i] = y_pred\n",
    "    dict_y_eval_rf[i] = Y_eval   \n",
    "    \n",
    "    dict_metrics_rf['mcc'].append(mcc_rf)\n",
    "    dict_metrics_rf['acc'].append(acc_rf)\n",
    "\n",
    "    print(f'fold{i} - MCC: {mcc_rf}, ACC: {acc_rf}') \n",
    "\n",
    "# 7. Aggregate and Mean of the metrics \n",
    "\n",
    "agg_y_pred_rf = list(itertools.chain.from_iterable(dict_y_pred_rf.values()))\n",
    "agg_y_eval_rf = list(itertools.chain.from_iterable(dict_y_eval_rf.values()))\n",
    "    \n",
    "agg_mcc_rf = matthews_corrcoef(agg_y_eval_rf, agg_y_pred_rf)\n",
    "agg_acc_rf = balanced_accuracy_score(agg_y_eval_rf, agg_y_pred_rf, adjusted = False)\n",
    "\n",
    "print(f' Aggregate MCC: {agg_mcc_rf} - Aggregate ACC {agg_acc_rf}')\n",
    "\n",
    "mean_mcc_rf = statistics.mean(list(dict_metrics_rf['mcc']))\n",
    "mean_acc_rf = statistics.mean(list(dict_metrics_rf['acc']))\n",
    "\n",
    "print(f'MCC mean: {mean_mcc_rf} ; ACC mean : {mean_acc_rf}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bdc09aa6ab4e98eab535ceedfab49fe19acfa6165900f66f90fd3791285f476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
